# LLM-Generated Contextual anomaly generation

import torch
from torch_geometric.data import Data
from torch_geometric.utils import k_hop_subgraph
from .openai_query import send_query_to_openai
from .anomaly_list import ANOMALY_TYPE_LIST
from .utils import encode_text
from typing import List
from .prompts import SYSTEM_PROMPT, USER_PROMPT_CORA
from collections import defaultdict

# ------------- PROMPT -------------

def llm_generated_contextual_anomaly_generator(data: Data, dataset_name: str, n: int, anomaly_type: int, random_seed: int, k_neighbors: int) -> Data:
    """
    Generate LLM-Generated Contextual anomaly for text-attributed graph
    """
    if ANOMALY_TYPE_LIST[anomaly_type] != "LLM-Generated Contextual Anomaly":
        raise ValueError(f"Invalid anomaly type: {anomaly_type}")
    if "cora" in dataset_name.lower():
        data = cora_llm_generated_contextual_anomaly_generator(data, n, anomaly_type, random_seed, k_neighbors)
    else:
        raise ValueError(f"Dataset name: {dataset_name} is not implemented")
    return data

def cora_llm_generated_contextual_anomaly_generator(data: Data, n: int, anomaly_type: int, random_seed: int, k_neighbors: int) -> Data:
    """
    Generate LLM-Generated Contextual anomaly for cora dataset
    cora has the following attributes:
    .raw_texts: List[str] the original text of nodes
    .category_names: List[str] the category of nodes
    .label_names: List[str], 7 labels: ['Rule_Learning', 'Neural_Networks', 'Case_Based', 'Genetic_Algorithms', 'Theory', 'Reinforcement_Learning', 'Probabilistic_Methods']
    .x: torch.Tensor, shape: torch.Size([2708, 384]), dtype: torch.float32
    .raw_text: List[str], the original text of nodes
    .val_masks: List[torch.Tensor], length: 10, element type: <class 'torch.Tensor'>
    .edge_index: torch.Tensor, shape: torch.Size([2, 10858]), dtype: torch.int64
    .train_masks: List[torch.Tensor], length: 10, element type: <class 'torch.Tensor'>
    .y: torch.Tensor, shape: torch.Size([2708]), dtype: torch.int64
    .test_masks: List[torch.Tensor], length: 10, element type: <class 'torch.Tensor'>

    Optional:
    .processed_text: List[str], the processed text of nodes
    .anomaly_labels: torch.Tensor, shape: torch.Size([2708]), dtype: torch.int64, the label of anomaly, 0 for normal, 1 for anomaly
    .anomaly_types: List[int], the type of anomaly
    .updated_x: torch.Tensor, shape: torch.Size([2708, 384]), dtype: torch.float32, the updated text embeddings of nodes
    """
    raw_text = data.raw_text
    node_num = len(raw_text)
    # get the index of normal nodes
    if hasattr(data, "anomaly_labels"):
        normal_idxs = (data.anomaly_labels == 0).nonzero(as_tuple=True)[0]
    else:
        normal_idxs = torch.arange(node_num)
    # if the number of normal nodes is less than n, raise error
    if normal_idxs.shape[0] < n:
        raise ValueError(f"The number of normal nodes is less than n: {normal_idxs.shape[0]} < {n}")
    # randomly select n nodes
    gen = torch.Generator(device=normal_idxs.device).manual_seed(int(random_seed))
    perm = torch.randperm(normal_idxs.numel(), generator=gen, device=normal_idxs.device)
    selected_idxs = normal_idxs[perm[:n]]
    # generate LLM-Generated Contextual anomaly
    data = llm_generated_contextual_anomaly(data, selected_idxs, anomaly_type, k_neighbors)
    # encode the text to embeddings
    data = encode_text(data)
    # The updated embeddings should be stored in data.updated_x
    return data

# LLM-Generated Contextual anomaly generation
def llm_generated_contextual_anomaly(data: Data, selected_idxs: torch.Tensor, anomaly_type: int, k_neighbors: int) -> Data:
    """
    Generate LLM-Generated Contextual anomaly
    replace the original text with the text generated by LLM
    """
    print("Generating LLM-Generated Contextual anomaly...")

    # step 1: initialize the processed text, anomaly labels, and anomaly types
    processed_text = data.raw_text.copy() if not hasattr(data, "processed_text") else data.processed_text.copy()
    anomaly_labels = torch.zeros(len(processed_text), dtype=torch.int64, device=data.x.device) if not hasattr(data, "anomaly_labels") else data.anomaly_labels.clone()
    anomaly_types = [0] * len(processed_text) if not hasattr(data, "anomaly_types") else data.anomaly_types.copy()

    # step 2: replace the original text with the text generated by LLM
    for idx in selected_idxs.tolist():
        print(f"Generating LLM-Generated Contextual anomaly for node {idx}...")
        print(f"Original text: {data.raw_text[idx]}")
        LLM_text = generate_LLM_text(data, idx, k_neighbors)
        print(f"\nLLM-Generated text: {LLM_text}")
        processed_text[idx] = LLM_text
        anomaly_labels[idx] = 1
        anomaly_types[idx] = anomaly_type

    # step 3: update the data
    data.processed_text = processed_text
    data.anomaly_labels = anomaly_labels
    data.anomaly_types = anomaly_types
    print("LLM-Generated Contextual anomaly generation completed")
    return data

# generate the text generated by LLM
def generate_LLM_text(data: Data, idx: int, k_neighbors: int) -> str:
    """
    Generate the text generated by LLM
    """
    # step 1: get all label names
    label_names = data.label_names.copy()

    # step 2: delete the label name of node idx from label_names
    node_label = data.category_names[idx]
    if node_label in label_names:
        label_names.remove(node_label)
    
    # step 3: start from the first hop neighbor, delete the most appeared label name until only one label name is left
    for i in range(k_neighbors):
        neighbors = get_k_hop_neighbors(data, idx, i+1)
        # get the label names of the neighbors in the descending order of the count
        sorted_label_names = count_and_sort_label_names(data, neighbors)
        index = 0
        while (len(label_names) > 1 and index < len(sorted_label_names)):
            current_label_name = sorted_label_names[index]
            if current_label_name in label_names:
                label_names.remove(current_label_name)
            index += 1
        if len(label_names) == 1:
            break
        
    # step 4: get the selected label name
    selected_label_name = label_names[0]

    # step 5: formulate the prompt and send the query to OpenAI
    node_label_name = data.category_names[idx]
    raw_text = data.raw_text[idx]
    system_prompt = SYSTEM_PROMPT
    user_prompt = USER_PROMPT_CORA.format(label_name=node_label_name, designated_label=selected_label_name, raw_text=raw_text)
    print(f"\nUser prompt: {user_prompt}")
    return send_query_to_openai(user_prompt=user_prompt, system_prompt=system_prompt)


def get_k_hop_neighbors(data: Data, idx: int, k: int)-> List[int]:
    """
    Get the k-hop neighbors of the node
    """
    if k == 0:
        return []
    # get the k-hop subgraph
    subset_k, _, _, _ = k_hop_subgraph(idx, k, data.edge_index)
    if k == 1:
        exact_k = subset_k[subset_k != idx].tolist()
        return exact_k
    # get k-1 hop subgraph
    subset_k_1, _, _, _ = k_hop_subgraph(idx, k-1, data.edge_index)
    # get the neighbors of the node
    set_k   = set(subset_k.tolist())
    set_k_1 = set(subset_k_1.tolist())
    exact_k = list(set_k - set_k_1 - {idx})
    return exact_k


def count_and_sort_label_names(data: Data, neighbors: List[int]) -> List[str]:
    """
    Count the label name of the neighbors and sort the label names by the count
    Sort in descending order
    """
    label_name_count = defaultdict(int)
    for neighbor in neighbors:
        label_name_count[data.category_names[neighbor]] += 1
    sorted_label_name_count = sorted(label_name_count.items(), key=lambda x: x[1], reverse=True)
    return [label_name for label_name, _ in sorted_label_name_count]